{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anikcse19/Books-site-with-responsive/blob/main/Thesis_Work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDVz5lkkE-bV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d99PPp_OJQEd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq-Q-_sNc0Lo"
      },
      "source": [
        "imported batting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAm90Xmnc559"
      },
      "outputs": [],
      "source": [
        "batting_data=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Batting list/Batting dataset (1).xlsx - Sheet1.csv',encoding= 'unicode_escape')\n",
        "batting_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANG3jZ1-LPrb"
      },
      "outputs": [],
      "source": [
        "batting_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snDySZsnLVkg"
      },
      "outputs": [],
      "source": [
        "batting_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEfKCORqdCa0"
      },
      "source": [
        "Find coorelation of batting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gHxORg-QAhK"
      },
      "outputs": [],
      "source": [
        "batting_data.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOP7gQzHNxxl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "corr=batting_data.corr()\n",
        "sns.heatmap(corr,annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oetfS0RcAVX"
      },
      "outputs": [],
      "source": [
        "batting_data_updated=batting_data.drop('Minutes', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5ScXE3TfWVk"
      },
      "outputs": [],
      "source": [
        "batting_data_updated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-fM7vjZdLjP"
      },
      "source": [
        "Imported Batting weather dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOzKeJkndOKI"
      },
      "outputs": [],
      "source": [
        "batting_weather_dataset=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Weather Dataset/Weather Dataset - Sheet1.csv')\n",
        "batting_weather_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMTXWl5-dytH"
      },
      "outputs": [],
      "source": [
        "batting_weather_dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DBSyl5Ud8yV"
      },
      "source": [
        "Find coorelation of weather dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVoZD6HheATA"
      },
      "outputs": [],
      "source": [
        "batting_weather_dataset.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzGICkHBeFQj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "corr=batting_weather_dataset.corr()\n",
        "sns.heatmap(corr,annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q32G9S2XeYcE"
      },
      "outputs": [],
      "source": [
        "batting_weather_dataset_updated=batting_weather_dataset.drop('Feels',axis=1)\n",
        "batting_weather_dataset_updated=batting_weather_dataset_updated.drop('Gust',axis=1)\n",
        "batting_weather_dataset_updated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui00gF_1tHNx"
      },
      "source": [
        "Bowling weather dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5S01JF9tKZH"
      },
      "outputs": [],
      "source": [
        "bowling_weather_dataset=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Bowling Weather Dataset/Bowling weather dataset - Sheet1.csv')\n",
        "bowling_weather_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNnVwy0Ztixp"
      },
      "outputs": [],
      "source": [
        "bowling_weather_dataset.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjN1FL45txVL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "corr=batting_weather_dataset.corr()\n",
        "sns.heatmap(corr,annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7vWQE7rtzEf"
      },
      "outputs": [],
      "source": [
        "bowling_weather_dataset_updated=bowling_weather_dataset.drop('Feels',axis=1)\n",
        "bowling_weather_dataset_updated=bowling_weather_dataset_updated.drop('Gust',axis=1)\n",
        "bowling_weather_dataset_updated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3JGZNWnuF10"
      },
      "source": [
        "Imported Fielding Weather Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXXjQ54FuKKm"
      },
      "outputs": [],
      "source": [
        "fielding_weather_dataset=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Bowling Weather Dataset/Bowling weather dataset - Sheet1.csv')\n",
        "fielding_weather_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9kurtH2uj9J"
      },
      "outputs": [],
      "source": [
        "fielding_weather_dataset_updated=fielding_weather_dataset.drop('Feels',axis=1)\n",
        "fielding_weather_dataset_updated=fielding_weather_dataset_updated.drop('Gust',axis=1)\n",
        "fielding_weather_dataset_updated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82debw1JOXTe"
      },
      "source": [
        "Imported Bowling Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6QOr8a5OdM3"
      },
      "outputs": [],
      "source": [
        "bowling_dataset=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Bowling List/Bowling_data - Bowling_data (1).csv')\n",
        "bowling_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeIMLYVpfARS"
      },
      "outputs": [],
      "source": [
        "bowling_dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrisGp54M_Jx"
      },
      "outputs": [],
      "source": [
        "bowling_dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE0kFpdZNHt3"
      },
      "outputs": [],
      "source": [
        "bowling_dataset.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ-oQ7JaNO9m"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "corr=bowling_dataset.corr()\n",
        "sns.heatmap(corr,annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KNArtbTqbVP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDbb8_GSxCZy"
      },
      "source": [
        "Individual Player performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r2D0YjUxGzd"
      },
      "outputs": [],
      "source": [
        "def get_batting_consistency(data, name):\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Filter the DataFrame to only include rows for the specified player name\n",
        "    player_df = df.loc[df['Name'] == name]\n",
        "    \n",
        "    # Create a list of dictionaries representing the stats for each occurrence of the name\n",
        "    stats_list = []\n",
        "    total_runs = 0\n",
        "    total_balls=0\n",
        "    innings=0\n",
        "    not_out=0\n",
        "    average=0\n",
        "    centuries=0\n",
        "    fiftees=0\n",
        "    zeros=0\n",
        "    for i in range(len(player_df)):\n",
        "\n",
        "\n",
        "        innings=innings+1\n",
        "        desc= player_df.iloc[i]['Description']\n",
        "        if (desc=='not out'):\n",
        "          not_out=not_out+1\n",
        "        balls= player_df.iloc[i]['Balls']\n",
        "        runs= player_df.iloc[i]['Runs']\n",
        "        if (runs>=100):\n",
        "          centuries=centuries+1\n",
        "        if (runs>=50 and runs<100):\n",
        "          fiftees=fiftees+1\n",
        "        if (runs==0):\n",
        "          zeros=zeros+1\n",
        "        \n",
        "        stats = {\n",
        "            'description': player_df.iloc[i]['Description'],\n",
        "            'runs': player_df.iloc[i]['Runs'],\n",
        "            'balls': player_df.iloc[i]['Balls'],\n",
        "            'fours': player_df.iloc[i]['Fours'],\n",
        "            'sixes': player_df.iloc[i]['Sixes']\n",
        "        }\n",
        "        total_runs += player_df.iloc[i]['Runs']\n",
        "        total_balls+= player_df.iloc[i]['Balls']\n",
        "        \n",
        "        stats_list.append(stats)\n",
        "    try:\n",
        "      average=total_runs/(innings-not_out)\n",
        "    except:\n",
        "      average=0\n",
        "\n",
        "    strike_rate=(total_runs/total_balls)*100\n",
        "\n",
        "    Consistency = round(0.4262*average + 0.2566*innings + 0.1510*strike_rate + 0.0787*centuries + 0.0556*fiftees - 0.0328*zeros,2)\n",
        "    \n",
        "    return Consistency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93rZvwO1xLTl"
      },
      "outputs": [],
      "source": [
        "batting_consistency = get_batting_consistency(batting_data_updated, 'Afif Hossain')\n",
        "batting_form=batting_consistency\n",
        "batting_opposition=batting_consistency\n",
        "\n",
        "print(batting_consistency)\n",
        "print(batting_form)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igZql_atAzxK"
      },
      "outputs": [],
      "source": [
        "def get_batting_venue(data, name):\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Filter the DataFrame to only include rows for the specified player name\n",
        "    player_df = df.loc[df['Name'] == name]\n",
        "    \n",
        "    # Create a list of dictionaries representing the stats for each occurrence of the name\n",
        "    stats_list = []\n",
        "    total_runs = 0\n",
        "    total_balls=0\n",
        "    innings=0\n",
        "    not_out=0\n",
        "    average=0\n",
        "    centuries=0\n",
        "    fiftees=0\n",
        "    zeros=0\n",
        "    hs=0\n",
        "    for i in range(len(player_df)):\n",
        "\n",
        "\n",
        "        innings=innings+1\n",
        "        desc= player_df.iloc[i]['Description']\n",
        "        if (desc=='not out'):\n",
        "          not_out=not_out+1\n",
        "        balls= player_df.iloc[i]['Balls']\n",
        "        runs= player_df.iloc[i]['Runs']\n",
        "        if (runs>hs):\n",
        "          hs=runs\n",
        "        if (runs>=100):\n",
        "          centuries=centuries+1\n",
        "        if (runs>=50 and runs<100):\n",
        "          fiftees=fiftees+1\n",
        "        if (runs==0):\n",
        "          zeros=zeros+1\n",
        "        \n",
        "        stats = {\n",
        "            'description': player_df.iloc[i]['Description'],\n",
        "            'runs': player_df.iloc[i]['Runs'],\n",
        "            'balls': player_df.iloc[i]['Balls'],\n",
        "            'fours': player_df.iloc[i]['Fours'],\n",
        "            'sixes': player_df.iloc[i]['Sixes']\n",
        "        }\n",
        "        total_runs += player_df.iloc[i]['Runs']\n",
        "        total_balls+= player_df.iloc[i]['Balls']\n",
        "\n",
        "        \n",
        "        stats_list.append(stats)\n",
        "    average=total_runs/(innings-not_out)\n",
        "    strike_rate=(total_runs/total_balls)*100\n",
        "  \n",
        "\n",
        "    Consistency = round(0.4262*average + 0.2566*innings + 0.1510*strike_rate + 0.0787*centuries + 0.0556*fiftees -0.0328*hs ,2)\n",
        "    \n",
        "    return Consistency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGW9biBFBSkR"
      },
      "outputs": [],
      "source": [
        "batting_venue=get_batting_venue(batting_data_updated,'Tamim Iqbal')\n",
        "print(batting_venue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsFDmjCD2oYL"
      },
      "outputs": [],
      "source": [
        "def get_bolwer_consistency(data, name):\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Filter the DataFrame to only include rows for the specified player name\n",
        "    player_df = df.loc[df['Name'] == name]\n",
        "    \n",
        "    # Create a list of dictionaries representing the stats for each occurrence of the name\n",
        "    stats_list = []\n",
        "    total_overs = 0\n",
        "    total_runs=0\n",
        "    total_wickets=0\n",
        "    innings=0\n",
        "    fifer=0\n",
        "    for i in range(len(player_df)):\n",
        "\n",
        "\n",
        "        wickets=player_df.iloc[i]['Bowler_Wickets']\n",
        "        if(wickets==5):\n",
        "          fifer=fifer+1\n",
        "\n",
        "        innings=innings+1\n",
        "        total_overs += player_df.iloc[i]['Overs']\n",
        "        total_wickets += player_df.iloc[i]['Bowler_Wickets']\n",
        "        total_runs += player_df.iloc[i]['Runs']\n",
        "\n",
        "        \n",
        "        stats_list.append(stats)\n",
        "    strike_rate=round((total_overs*6/total_wickets),2)\n",
        "    average= round(total_runs/total_wickets,2)\n",
        "\n",
        "    Consistency = round(0.4174*total_overs + 0.2634*innings + 0.1602*strike_rate + 0.0975*average + 0.0615*fifer,2)\n",
        "    \n",
        "    return Consistency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU2OPUzj20Ck"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "bowling_consistency= get_bolwer_consistency(bowling_dataset, 'Mehidy Hasan Miraz')\n",
        "\n",
        "print(bowling_consistency)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gyC8O1A8nh_"
      },
      "outputs": [],
      "source": [
        "def get_bowler_form(data, name):\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Filter the DataFrame to only include rows for the specified player name\n",
        "    player_df = df.loc[df['Name'] == name]\n",
        "    \n",
        "    # Create a list of dictionaries representing the stats for each occurrence of the name\n",
        "    stats_list = []\n",
        "    total_overs = 0\n",
        "    total_runs=0\n",
        "    total_wickets=0\n",
        "    innings=0\n",
        "    fifer=0\n",
        "    for i in range(len(player_df)):\n",
        "\n",
        "\n",
        "        wickets=player_df.iloc[i]['Bowler_Wickets']\n",
        "        if(wickets==5):\n",
        "          fifer=fifer+1\n",
        "\n",
        "        innings=innings+1\n",
        "        total_overs += player_df.iloc[i]['Overs']\n",
        "        total_wickets += player_df.iloc[i]['Bowler_Wickets']\n",
        "        total_runs += player_df.iloc[i]['Runs']\n",
        "\n",
        "        \n",
        "        stats_list.append(stats)\n",
        "    strike_rate=round((total_overs*6/total_wickets),2)\n",
        "    average= round(total_runs/total_wickets,2)\n",
        "\n",
        "    form = round(0.3269*total_overs + 0.2846*innings + 0.1877*strike_rate + 0.1210*average + 0.0798*fifer,2)\n",
        "    \n",
        "    return form \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLrnV1H__Y23"
      },
      "outputs": [],
      "source": [
        "bowling_form=get_bowler_form(bowling_dataset, 'Mehidy Hasan Miraz')\n",
        "print(bowling_form)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cEMKMjL_3WK"
      },
      "outputs": [],
      "source": [
        "def get_bowling_opposition(data, name):\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Filter the DataFrame to only include rows for the specified player name\n",
        "    player_df = df.loc[df['Name'] == name]\n",
        "    \n",
        "    # Create a list of dictionaries representing the stats for each occurrence of the name\n",
        "    stats_list = []\n",
        "    total_overs = 0\n",
        "    total_runs=0\n",
        "    total_wickets=0\n",
        "    innings=0\n",
        "    fifer=0\n",
        "    for i in range(len(player_df)):\n",
        "\n",
        "\n",
        "        wickets=player_df.iloc[i]['Bowler_Wickets']\n",
        "        if(wickets==5):\n",
        "          fifer=fifer+1\n",
        "\n",
        "        innings=innings+1\n",
        "        total_overs += player_df.iloc[i]['Overs']\n",
        "        total_wickets += player_df.iloc[i]['Bowler_Wickets']\n",
        "        total_runs += player_df.iloc[i]['Runs']\n",
        "\n",
        "        \n",
        "        stats_list.append(stats)\n",
        "    strike_rate=round((total_overs*6/total_wickets),2)\n",
        "    average= round(total_runs/total_wickets,2)\n",
        "\n",
        "    opposition= round(0.3177*total_overs + 0.3177*innings + 0.1933*strike_rate + 0.1465*average + 0.0943*fifer,2)\n",
        "    \n",
        "    return opposition \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxSrF9IyAUdy"
      },
      "outputs": [],
      "source": [
        "bowling_opposition=get_bowling_opposition(bowling_dataset, 'Mehidy Hasan Miraz')\n",
        "print(bowling_opposition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O-Qe_XPAnaA"
      },
      "outputs": [],
      "source": [
        "def get_bowling_venue(data, name):\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Filter the DataFrame to only include rows for the specified player name\n",
        "    player_df = df.loc[df['Name'] == name]\n",
        "    \n",
        "    # Create a list of dictionaries representing the stats for each occurrence of the name\n",
        "    stats_list = []\n",
        "    total_overs = 0\n",
        "    total_runs=0\n",
        "    total_wickets=0\n",
        "    innings=0\n",
        "    fifer=0\n",
        "    for i in range(len(player_df)):\n",
        "\n",
        "\n",
        "        wickets=player_df.iloc[i]['Bowler_Wickets']\n",
        "        if(wickets==5):\n",
        "          fifer=fifer+1\n",
        "\n",
        "        innings=innings+1\n",
        "        total_overs += player_df.iloc[i]['Overs']\n",
        "        total_wickets += player_df.iloc[i]['Bowler_Wickets']\n",
        "        total_runs += player_df.iloc[i]['Runs']\n",
        "\n",
        "        \n",
        "        stats_list.append(stats)\n",
        "    strike_rate=round((total_overs*6/total_wickets),2)\n",
        "    average= round(total_runs/total_wickets,2)\n",
        "\n",
        "    venue= round(0.3018*total_overs + 0.2783*innings + 0.1836*strike_rate + 0.1391*average + 0.0972*fifer,2)\n",
        "    \n",
        "    return venue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2-1XkdrB9ws"
      },
      "outputs": [],
      "source": [
        "bowling_venue=get_bowling_venue(bowling_dataset, 'Mehidy Hasan Miraz')\n",
        "print(bowling_venue)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import fielding dataset\n",
        "fielding_dataset=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Fielding Dataset/Fielding Dataset - Sheet1.csv')\n",
        "fielding_dataset"
      ],
      "metadata": {
        "id": "Wz6IQCLihmmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fielding_success_rate(data, name):\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Filter the DataFrame to only include rows for the specified player name\n",
        "    player_df = df.loc[df['Name'] == name]\n",
        "\n",
        "    total_catches_taken = 0\n",
        "    total_run_out_taken = 0\n",
        "    total_catches_dropped = 0\n",
        "    total_runout_dropped = 0\n",
        "\n",
        "    for i in range(len(player_df)):\n",
        "        total_catches_taken += player_df.iloc[i]['Catches']\n",
        "        total_run_out_taken += player_df.iloc[i]['Run Outs']\n",
        "        total_catches_dropped += player_df.iloc[i]['Dropped catches']\n",
        "        total_runout_dropped += player_df.iloc[i]['Missed Runouts']\n",
        "\n",
        "    success_rate = (total_catches_taken + total_run_out_taken) / (total_catches_taken + total_run_out_taken + total_catches_dropped + total_runout_dropped)\n",
        "    success_rate=round(success_rate,2)\n",
        "    return success_rate\n"
      ],
      "metadata": {
        "id": "rdzeYUs3DNIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=get_fielding_success_rate(fielding_dataset,'Shakib Al Hasan')\n",
        "print(x)"
      ],
      "metadata": {
        "id": "KmJixK6nfZE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ydNC722f4A"
      },
      "source": [
        "***BattiNg PerformaNce PredictioN Module***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfyccvolptSQ"
      },
      "outputs": [],
      "source": [
        "batting_df=batting_data_updated\n",
        "batting_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP_rIH2kqF1b"
      },
      "outputs": [],
      "source": [
        "batting_weather_df=batting_weather_dataset_updated\n",
        "batting_weather_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-xXr4sBqrQG"
      },
      "outputs": [],
      "source": [
        "batting_merged_df = pd.merge(batting_df, batting_weather_df, on=['Match_id'])\n",
        "batting_merged_df.shape\n",
        "# columns_1= batting_merged_df.columns.tolist()\n",
        "# print(columns_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUa81c_YymvV"
      },
      "source": [
        "\n",
        "**Add Batting consistency and batting form into the dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzYU_hcKyub3"
      },
      "outputs": [],
      "source": [
        "# Iterate over rows of batting_merged_df\n",
        "for index, row in batting_merged_df.iterrows():\n",
        "    # Get the player name from the row\n",
        "    player_name = row['Name']\n",
        "    \n",
        "    # Calculate the batting consistency and form for the player\n",
        "    batting_consistency = get_batting_consistency(batting_merged_df, player_name)\n",
        "    batting_form = get_batting_consistency(batting_merged_df, player_name)\n",
        "    \n",
        "    # Set the values for the new columns in the row\n",
        "    batting_merged_df.at[index, 'batting_consistency'] = batting_consistency\n",
        "    batting_merged_df.at[index, 'batting_form'] = batting_form\n",
        "\n",
        "\n",
        "batting_merged_df\n",
        "# columns_1= batting_merged_df.columns.tolist()\n",
        "# print(columns_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gBs-VXjPnCQ"
      },
      "source": [
        "Match List imported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s2rT8LpPlCu"
      },
      "outputs": [],
      "source": [
        "match_list_df=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Match list data/match_lists_data - match_lists_data (1).csv')\n",
        "match_list_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sptJU5_ht1m3"
      },
      "outputs": [],
      "source": [
        "# columns_1= batting_merged_df.columns.tolist()\n",
        "# columns_2= match_list_df.columns.tolist()\n",
        "# # Print the column names\n",
        "# print(columns_1)\n",
        "# print(columns_2)\n",
        "\n",
        "# Get the column names as sets\n",
        "columns1 = set(batting_merged_df.columns)\n",
        "columns2 = set(match_list_df.columns)\n",
        "\n",
        "# Find the common columns\n",
        "common_cols = columns1.intersection(columns2)\n",
        "\n",
        "# Print the number of common columns and their names\n",
        "print(\"Number of common columns:\", len(common_cols))\n",
        "print(\"Common column names:\", list(common_cols))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6De8zL43xfA"
      },
      "source": [
        "Merged Batting_merged_df and Match list after droping the duplicate columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELv0n_kr370O"
      },
      "outputs": [],
      "source": [
        "match_list_df= match_list_df.drop(['Date', 'Venue', 'Batting_Session',], axis=1)\n",
        "match_list_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8lcpU5vIDf"
      },
      "source": [
        "**Check commoN columNs betwee two dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA7somQA4Uy-"
      },
      "outputs": [],
      "source": [
        "# Get the column names as sets\n",
        "columns1 = set(batting_merged_df.columns)\n",
        "columns2 = set(match_list_df.columns)\n",
        "\n",
        "# Find the common columns\n",
        "common_cols = columns1.intersection(columns2)\n",
        "\n",
        "# Print the number of common columns and their names\n",
        "print(\"Number of common columns:\", len(common_cols))\n",
        "print(\"Common column names:\", list(common_cols))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61zMv84DvWeD"
      },
      "source": [
        "Merged Previous two dataset with match list dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8xdulnWTTvM"
      },
      "outputs": [],
      "source": [
        "batting_match_df = pd.merge(batting_merged_df, match_list_df, on='Match_id')\n",
        "print(batting_match_df)\n",
        "batting_match_df.shape\n",
        "columns_1= batting_match_df.columns.tolist()\n",
        "print(columns_1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdeBWz2x5gRN"
      },
      "source": [
        "Feature **Importance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx3BPPsF5U0m"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "\n",
        "# replace '-' with NaN\n",
        "batting_match_df = batting_match_df.replace('-', np.nan)\n",
        "\n",
        "# fill NaN values with a numeric value\n",
        "batting_match_df = batting_match_df.fillna(0)\n",
        "\n",
        "# separate the target variable\n",
        "y = batting_match_df['Result']\n",
        "# print(X)\n",
        "X = batting_match_df.drop(columns=['Result','URL_Text','Url text'])\n",
        "# print(X)\n",
        "\n",
        "\n",
        "# encode categorical variables\n",
        "cat_cols = ['Name', 'Description', 'Batting_Session', 'Date', 'Venue', 'Opposition', 'Ground', 'Bowling_Session', 'Toss_Win']\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X[cat_cols].apply(encoder.fit_transform)\n",
        "X_encoded = X_encoded.join(X.drop(cat_cols, axis=1))\n",
        "\n",
        "# print(X_encoded)\n",
        "# print(X_encoded.max())\n",
        "# print(X_encoded.min())\n",
        "\n",
        "# replace infinity with NaN and drop rows containing NaN values\n",
        "X_encoded.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_encoded.dropna(inplace=True)\n",
        "y = y[X_encoded.index]\n",
        "\n",
        "\n",
        "\n",
        "# scale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# print(X_scaled)\n",
        "# feature selection using Random Forest\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "\n",
        "# fit the model on the selected features\n",
        "rfc.fit(X_scaled, y)\n",
        "\n",
        "# get the important feature names\n",
        "feature_names = X_encoded.columns.tolist()\n",
        "\n",
        "\n",
        "# plot feature importance\n",
        "importance = rfc.feature_importances_\n",
        "sorted_idx = np.argsort(importance)\n",
        "\n",
        "plt.barh(range(len(sorted_idx)), importance[sorted_idx])\n",
        "plt.yticks(range(len(sorted_idx)), X_encoded.columns[sorted_idx])\n",
        "plt.xlabel('Random Forest Feature Importance')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYn77ffzWa7t"
      },
      "source": [
        "Run Random forest model to predict batting performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_hQQIO-Wd9S"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# print(X_scaled.columns)\n",
        "\n",
        "batting_match_df.replace([np.inf, -np.inf],np.nan,inplace=True)\n",
        "batting_match_df.dropna(inplace=True)\n",
        "\n",
        "# separate the target variables\n",
        "y = batting_match_df[['Runs', 'Balls', 'Fours', 'Sixes', 'Batting_position']]\n",
        "# y_runs = y['Runs']\n",
        "# y_balls = y['Balls']\n",
        "# y_fours = y['Fours']\n",
        "# y_sixes = y['Sixes']\n",
        "# y_position = y['Batting_position']\n",
        "\n",
        "X = batting_match_df[['Opposition','Target','Score','Strike_Rate','Toss_Win','Temp','Venue','Overs','Batting_Session','Wind','Pressure','Innings','batting_consistency']]\n",
        "\n",
        "# encode categorical variables\n",
        "cat_cols = ['Venue', 'Opposition', 'Batting_Session','Toss_Win']\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X[cat_cols].apply(encoder.fit_transform)\n",
        "X_encoded = X_encoded.join(X.drop(cat_cols, axis=1))\n",
        "\n",
        "\n",
        "# scale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# print(y_train)\n",
        "\n",
        "# train the linear regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of lR model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print('\\n\\n')\n",
        "print(\"*********************Overall Result of Linear Regression Model*********************************\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n",
        "print('\\n\\n')\n",
        "\n",
        "#train the random forest model\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of random forest model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(\"***********Overall Result of Random forest Model******************\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n",
        "print('\\n\\n')\n",
        "\n",
        "\n",
        "# train the Gradient Boosting Regressor model\n",
        "gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "multi_gbr = MultiOutputRegressor(gbr)\n",
        "multi_gbr.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = multi_gbr.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of gradiant boosting model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"***********Overall Result of Gradiant Boosting Model******************\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n",
        "\n",
        "print(\"******************Individual result********************\")\n",
        "for i, col in enumerate(y.columns):\n",
        "    rmse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i], squared=False)\n",
        "    r_squared = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
        "    print(col)\n",
        "    print('RMSE:', rmse)\n",
        "    print('R-squared:', r_squared)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gdOh0bVcu7B"
      },
      "source": [
        "**Performance between training data and testing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIomExbncx5-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# make predictions on the training set\n",
        "y_train_pred = rfc.predict(X_train)\n",
        "\n",
        "# calculate RMSE and R-squared values for training set\n",
        "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
        "r_squared_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "print('Training set RMSE:', rmse_train)\n",
        "print('Training set R-squared:', r_squared_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_test_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values for testing set\n",
        "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
        "r_squared_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print('Testing set RMSE:', rmse_test)\n",
        "print('Testing set R-squared:', r_squared_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfMGLwsrf_Ns"
      },
      "outputs": [],
      "source": [
        "# plot actual vs predicted runs\n",
        "c=y_test.columns.tolist()\n",
        "print(c)\n",
        "\n",
        "plt.scatter(y_test['Runs'], y_pred[:,0])\n",
        "plt.xlabel('Actual Runs scored')\n",
        "plt.ylabel('Predicted Runs scored')\n",
        "plt.title('Actual vs Predicted Run scored')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzYrmrMLumy4"
      },
      "outputs": [],
      "source": [
        "# plot actual vs predicted balls faced\n",
        "plt.scatter(y_test['Balls'], y_pred[:,1])\n",
        "plt.xlabel('Actual Ball faced')\n",
        "plt.ylabel('Predicted ball faced')\n",
        "plt.title('Actual vs Predicted Ball faced')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icA0SxGzv8Q_"
      },
      "outputs": [],
      "source": [
        "# plot actual vs predicted Fours\n",
        "plt.scatter(y_test['Fours'], y_pred[:,2])\n",
        "plt.xlabel('Actual Fours')\n",
        "plt.ylabel('Predicted Fours')\n",
        "plt.title('Actual vs Predicted Fours')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91FLm00DwIq-"
      },
      "outputs": [],
      "source": [
        "# plot actual vs predicted Sixes\n",
        "plt.scatter(y_test['Sixes'], y_pred[:,3])\n",
        "plt.xlabel('Actual Sixes')\n",
        "plt.ylabel('Predicted Sixes')\n",
        "plt.title('Actual vs Predicted Sixes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7sCVmDswTvl"
      },
      "outputs": [],
      "source": [
        "# plot actual vs predicted battiNg Position\n",
        "plt.scatter(y_test['Batting_position'], y_pred[:,4])\n",
        "plt.xlabel('Actual Batting_position')\n",
        "plt.ylabel('Predicted Batting_position')\n",
        "plt.title('Actual vs Predicted Batting_position')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkrD3XkW3OuV"
      },
      "source": [
        "***BowliNg PerfromaNce PredictioN Module***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHWxftYn3VIb"
      },
      "outputs": [],
      "source": [
        "bowling_df=bowling_dataset\n",
        "bowling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ95Cqea6qjh"
      },
      "outputs": [],
      "source": [
        "bowling_weather_df=bowling_weather_dataset_updated\n",
        "bowling_weather_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFG7x1Sx7H7X"
      },
      "source": [
        "Merged BowliNg dataset aNd BowliNg weather dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7m5rnwJ7ORr"
      },
      "outputs": [],
      "source": [
        "bowling_merged_df = pd.merge(bowling_df, bowling_weather_df, on=['Match_id'])\n",
        "bowling_merged_df.shape\n",
        "bowling_merged_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYkomqEt_rUH"
      },
      "source": [
        "Add bowling consistency, bowling form, bowling opposition, bowling venue into the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqX532CI_2CJ"
      },
      "outputs": [],
      "source": [
        "# Iterate over rows of bowling_merged_df\n",
        "for index, row in bowling_merged_df.iterrows():\n",
        "    # Get the player name from the row\n",
        "    player_name = row['Name']\n",
        "    \n",
        "    # Calculate the batting consistency and form for the player\n",
        "    bowling_consistency = get_bolwer_consistency(bowling_merged_df, player_name)\n",
        "    bowling_form = get_bowler_form(bowling_merged_df, player_name)\n",
        "    bowling_opposition=get_bowling_opposition(bowling_merged_df, player_name)\n",
        "    bowling_venue= get_bowling_venue(bowling_merged_df, player_name)\n",
        "    \n",
        "    # Set the values for the new columns in the row\n",
        "    bowling_merged_df.at[index, 'bowling_consistency'] = bowling_consistency\n",
        "    bowling_merged_df.at[index, 'bowling_form'] = bowling_form\n",
        "    bowling_merged_df.at[index, 'bowling_opposition']=bowling_opposition\n",
        "    bowling_merged_df.at[index, 'bowling_venue']=bowling_venue\n",
        "\n",
        "\n",
        "\n",
        "columns_1= bowling_merged_df.columns.tolist()\n",
        "print(columns_1)\n",
        "bowling_merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5bhXvk8-bvM"
      },
      "outputs": [],
      "source": [
        "match_list_df_1=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Match list data/match_lists_data - match_lists_data (3).csv')\n",
        "match_list_df_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ2gAS0bDMYq"
      },
      "outputs": [],
      "source": [
        "columns_1= bowling_merged_df.columns.tolist()\n",
        "columns_2= match_list_df_1.columns.tolist()\n",
        "# Print the column names\n",
        "print(columns_1)\n",
        "print(columns_2)\n",
        "\n",
        "# Get the column names as sets\n",
        "columns1 = set(bowling_merged_df.columns)\n",
        "columns2 = set(match_list_df_1.columns)\n",
        "\n",
        "# Find the common columns\n",
        "common_cols = columns1.intersection(columns2)\n",
        "\n",
        "# Print the number of common columns and their names\n",
        "print(\"Number of common columns:\", len(common_cols))\n",
        "print(\"Common column names:\", list(common_cols))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIjG2cw661wz"
      },
      "source": [
        "Drop duplicate columns without match id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48dtaTRa67dG"
      },
      "outputs": [],
      "source": [
        "match_list_df_1= match_list_df_1.drop(columns=['Url text','Venue','Bowling_Session','Date'], axis=1)\n",
        "match_list_df_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiJwSbZS9l0j"
      },
      "outputs": [],
      "source": [
        "bowling_match_df=pd.merge(bowling_merged_df,match_list_df_1,on=['Match_id'])\n",
        "bowling_match_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_1= bowling_match_df.columns.tolist()\n",
        "\n",
        "print(columns_1)\n"
      ],
      "metadata": {
        "id": "b6XuHAk9pSHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features importance of bolwing performance prediction**"
      ],
      "metadata": {
        "id": "oD57mMj-osp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace '-' with NaN\n",
        "bowling_match_df = bowling_match_df.replace('-', np.nan)\n",
        "\n",
        "# fill NaN values with a numeric value\n",
        "bowling_match_df = bowling_match_df.fillna(0)\n",
        "\n",
        "# separate the target variable\n",
        "y = bowling_match_df['Result']\n",
        "# print(X)\n",
        "X = bowling_match_df.drop(columns=['Result','URL_Text','Date','Match_id'])\n",
        "# print(X)\n",
        "\n",
        "\n",
        "# encode categorical variables\n",
        "cat_cols = ['Name', 'Batting_Session', 'Venue', 'Opposition', 'Ground', 'Bowling_Session', 'Toss_Win']\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X[cat_cols].apply(encoder.fit_transform)\n",
        "X_encoded = X_encoded.join(X.drop(cat_cols, axis=1))\n",
        "\n",
        "# print(X_encoded)\n",
        "# print(X_encoded.max())\n",
        "# print(X_encoded.min())\n",
        "\n",
        "# replace infinity with NaN and drop rows containing NaN values\n",
        "X_encoded.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_encoded.dropna(inplace=True)\n",
        "y = y[X_encoded.index]\n",
        "\n",
        "\n",
        "\n",
        "# scale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# print(X_scaled)\n",
        "# feature selection using Random Forest\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "\n",
        "# fit the model on the selected features\n",
        "rfc.fit(X_scaled, y)\n",
        "\n",
        "# get the important feature names\n",
        "feature_names = X_encoded.columns.tolist()\n",
        "\n",
        "\n",
        "# plot feature importance\n",
        "importance = rfc.feature_importances_\n",
        "sorted_idx = np.argsort(importance)\n",
        "\n",
        "plt.barh(range(len(sorted_idx)), importance[sorted_idx])\n",
        "plt.yticks(range(len(sorted_idx)), X_encoded.columns[sorted_idx])\n",
        "plt.xlabel('Random Forest Feature Importance')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "cqM7X9wko3PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Random forest model to predict bowling performance"
      ],
      "metadata": {
        "id": "WEHojNhvqk6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# print(X_scaled.columns)\n",
        "\n",
        "bowling_match_df.replace([np.inf, -np.inf],np.nan,inplace=True)\n",
        "bowling_match_df.dropna(inplace=True)\n",
        "\n",
        "# separate the target variable\n",
        "y = bowling_match_df[['Runs', 'Overs', 'Bowler_Wickets']]\n",
        "X = bowling_match_df[['Opposition','Econ','Toss_Win','Score','Temp','Venue','Bowling_Session','Dots','Total_Overs','Wind','Pressure','Innings','bowling_consistency','bowling_form','bowling_opposition','bowling_venue']]\n",
        "\n",
        "# encode categorical variables\n",
        "cat_cols = ['Venue', 'Opposition', 'Bowling_Session']\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X[cat_cols].apply(encoder.fit_transform)\n",
        "X_encoded = X_encoded.join(X.drop(cat_cols, axis=1))\n",
        "\n",
        "\n",
        "# scale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
        "\n",
        "\n",
        "# train the linear regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of lR model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(\"*********************Overall Result of Linear Regression Model*********************************\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n",
        "print('\\n\\n')\n",
        "\n",
        "# train the Gradient Boosting Regressor model\n",
        "gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "multi_gbr = MultiOutputRegressor(gbr)\n",
        "multi_gbr.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = multi_gbr.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of gradiant boostingg model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"*********************Overall Result of Gradiant boosting Model*********************************\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n",
        "print('\\n\\n')\n",
        "\n",
        "# train the random forest model\n",
        "rfc = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of random forest model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"********************Overall result of random forest model*******************************8\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n",
        "\n",
        "\n",
        "print(\"********************** Individual result***************************\")\n",
        "for i, col in enumerate(y.columns):\n",
        "    rmse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i], squared=False)\n",
        "    r_squared = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
        "    print(col)\n",
        "    print('RMSE:', rmse)\n",
        "    print('R-squared:', r_squared)\n",
        "\n",
        "# Concatenate predicted output values with input features in test set\n",
        "bowling_performance_data = pd.concat([pd.DataFrame(y_pred, columns=['Predicted_Runs', 'Predicted_Overs', 'Predicted_Wickets']), y_test.reset_index(drop=True)], axis=1)\n",
        "bowling_performance_data"
      ],
      "metadata": {
        "id": "FKylv5I_qppz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual impression of actual attributes and predicted attributes"
      ],
      "metadata": {
        "id": "-ZW7pO9W5m3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot actual vs predicted Runs conceded\n",
        "plt.scatter(y_test['Runs'], y_pred[:,0])\n",
        "plt.xlabel('Actual Runs conceded')\n",
        "plt.ylabel('Predicted Runs conceded ')\n",
        "plt.title('Actual vs Predicted Runs conceded')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lX3nQJ655uF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot actual vs predicted completed Overs\n",
        "plt.scatter(y_test['Overs'], y_pred[:,1])\n",
        "plt.xlabel('Actual completed overs')\n",
        "plt.ylabel('Predicted completed overs')\n",
        "plt.title('Actual vs Predicted completed overs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eXl7a6UG6D4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot actual vs predicted wickets taken\n",
        "plt.scatter(y_test['Bowler_Wickets'], y_pred[:,2])\n",
        "plt.xlabel('Actual Wickets taken')\n",
        "plt.ylabel('Predicted Wickets taken')\n",
        "plt.title('Actual vs Predicted Wickets taken')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "er1FUlaS6bis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fielding Performance Prediction"
      ],
      "metadata": {
        "id": "J3sOCwcXBvOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import fielding dataset\n",
        "fielding_dataset=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Fielding Dataset/Fielding Dataset - Sheet1.csv')\n",
        "fielding_dataset"
      ],
      "metadata": {
        "id": "FBoT15hCB0ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fielding_dataset.corr()"
      ],
      "metadata": {
        "id": "mdLF7bciCam-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge fileding dataset with weather dataset"
      ],
      "metadata": {
        "id": "8Qb1v6GPd7UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fielding_merged_df=pd.merge(fielding_dataset, fielding_weather_dataset_updated, on=['Match_id'])\n",
        "fielding_merged_df"
      ],
      "metadata": {
        "id": "sAAxkVurd_Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=fielding_merged_df.columns.tolist()\n",
        "print(columns)"
      ],
      "metadata": {
        "id": "SxHYDGgreWON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add fielding Success rate into the fielding dataset"
      ],
      "metadata": {
        "id": "2nI26nNTClMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over rows of batting_merged_df\n",
        "for index, row in fielding_merged_df.iterrows():\n",
        "    # Get the player name from the row\n",
        "    player_name = row['Name']\n",
        "    \n",
        "    # Calculate the batting consistency and form for the player\n",
        "    fielding_success_rate = get_fielding_success_rate(fielding_merged_df, player_name)\n",
        "    \n",
        "    # Set the values for the new columns in the row\n",
        "    fielding_merged_df.at[index, 'fielding_success_rate'] = fielding_success_rate\n",
        "\n",
        "\n",
        "\n",
        "columns_1= fielding_merged_df.columns.tolist()\n",
        "print(columns_1)\n",
        "fielding_merged_df"
      ],
      "metadata": {
        "id": "EYQb59wgCp_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_1= fielding_merged_df.columns.tolist()\n",
        "columns_2= match_list_df_1.columns.tolist()\n",
        "# Print the column names\n",
        "print(columns_1)\n",
        "print(columns_2)\n",
        "\n",
        "# Get the column names as sets\n",
        "columns1 = set(fielding_merged_df.columns)\n",
        "columns2 = set(match_list_df_1.columns)\n",
        "\n",
        "# Find the common columns\n",
        "common_cols = columns1.intersection(columns2)\n",
        "\n",
        "# Print the number of common columns and their names\n",
        "print(\"Number of common columns:\", len(common_cols))\n",
        "print(\"Common column names:\", list(common_cols))"
      ],
      "metadata": {
        "id": "NM5x8YC4lNn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merged fielding and weather dataset with match list dataset"
      ],
      "metadata": {
        "id": "kTAydNFmkOwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fielding_match_df=pd.merge(fielding_merged_df, match_list_df_1,on=['Match_id'])\n",
        "fielding_match_df"
      ],
      "metadata": {
        "id": "K8bvSjslkUoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features Importance of fielding Performance prediction"
      ],
      "metadata": {
        "id": "7leb5tDDlhV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace '-' with NaN\n",
        "fielding_match_df = fielding_match_df.replace('-', np.nan)\n",
        "\n",
        "# fill NaN values with a numeric value\n",
        "fielding_match_df = fielding_match_df.fillna(0)\n",
        "\n",
        "# separate the target variable\n",
        "y = fielding_match_df['Result']\n",
        "# print(X)\n",
        "X = fielding_match_df.drop(columns=['Result','URL_Text','Date','Match_id'])\n",
        "# print(X)\n",
        "\n",
        "\n",
        "# encode categorical variables\n",
        "cat_cols = ['Name', 'Batting_Session', 'Venue', 'Opposition', 'Ground', 'Bowling_Session', 'Toss_Win']\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X[cat_cols].apply(encoder.fit_transform)\n",
        "X_encoded = X_encoded.join(X.drop(cat_cols, axis=1))\n",
        "\n",
        "# print(X_encoded)\n",
        "# print(X_encoded.max())\n",
        "# print(X_encoded.min())\n",
        "\n",
        "# replace infinity with NaN and drop rows containing NaN values\n",
        "X_encoded.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_encoded.dropna(inplace=True)\n",
        "y = y[X_encoded.index]\n",
        "\n",
        "\n",
        "\n",
        "# scale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# print(X_scaled)\n",
        "# feature selection using Random Forest\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "\n",
        "# fit the model on the selected features\n",
        "rfc.fit(X_scaled, y)\n",
        "\n",
        "# get the important feature names\n",
        "feature_names = X_encoded.columns.tolist()\n",
        "\n",
        "\n",
        "# plot feature importance\n",
        "importance = rfc.feature_importances_\n",
        "sorted_idx = np.argsort(importance)\n",
        "\n",
        "plt.barh(range(len(sorted_idx)), importance[sorted_idx])\n",
        "plt.yticks(range(len(sorted_idx)), X_encoded.columns[sorted_idx])\n",
        "plt.xlabel('Random Forest Feature Importance')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Qgam9LhYlaPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run model to predict fielding performmance"
      ],
      "metadata": {
        "id": "3VTiovlvmCO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "fielding_match_df.replace([np.inf, -np.inf],np.nan,inplace=True)\n",
        "fielding_match_df.dropna(inplace=True)\n",
        "\n",
        "# separate the target variable\n",
        "y = fielding_match_df[['fielding_success_rate']]\n",
        "X = fielding_match_df[['Opposition','Toss_Win','Score','Temp','Cloud','Venue','Bowling_Session','Total_Overs','Wind','Pressure','Innings']]\n",
        "\n",
        "# encode categorical variables\n",
        "cat_cols = ['Venue', 'Opposition', 'Bowling_Session']\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X[cat_cols].apply(encoder.fit_transform)\n",
        "X_encoded = X_encoded.join(X.drop(cat_cols, axis=1))\n",
        "\n",
        "\n",
        "# scale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
        "\n",
        "\n",
        "# train the linear regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of lR model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(\"*********************Overall Result of Linear Regression Model*********************************\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n",
        "print('\\n\\n')\n",
        "\n",
        "# train the Gradient Boosting Regressor model\n",
        "gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "multi_gbr = MultiOutputRegressor(gbr)\n",
        "multi_gbr.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = multi_gbr.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of gradiant boostingg model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"*********************Overall Result of Gradiant boosting Model*********************************\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n",
        "print('\\n\\n')\n",
        "\n",
        "# train the random forest model\n",
        "rfc = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate RMSE and R-squared values of random forest model\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"********************Overall result of random forest model*******************************8\")\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r_squared)\n"
      ],
      "metadata": {
        "id": "bXIEB8y9mGsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot actual vs predicted wickets taken\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual fielding success rate')\n",
        "plt.ylabel('Predicted fielding success rate')\n",
        "plt.title('Actual vs Predicted fielding success rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fgdPI948yVkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Players Rating Model based on predicted batting, bowling and fielding performance**"
      ],
      "metadata": {
        "id": "ljTq8TD5BA43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all necessary dataset"
      ],
      "metadata": {
        "id": "FCkbd1ydBi_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_batting=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Batting list/changed_Batting dataset.csv')\n",
        "dataset_batting"
      ],
      "metadata": {
        "id": "pAaLPJX5BhNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_bowling=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Bowling List/changed_Bowling_data.csv')\n",
        "dataset_bowling"
      ],
      "metadata": {
        "id": "TFMX4G-iCqOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_batting_weather=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Weather Dataset/changed_batting_weather_data.csv')\n",
        "dataset_batting_weather"
      ],
      "metadata": {
        "id": "QcMaiagjCy7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_bowling_weather=pd.read_csv('/content/drive/MyDrive/Thesis Data set/Bowling Weather Dataset/changed_bowling_weather_data.csv')\n",
        "dataset_bowling_weather"
      ],
      "metadata": {
        "id": "GBzu7rJAC8xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBRK30-RDHzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge bating_match_df, Bowling_match_df and fielding_match_df together\n",
        "\n",
        "# merged_all_dataset=pd.merge(batting_match_df,bowling_match_df,on=['Match_id'])\n",
        "# merged_all_dataset\n",
        "\n",
        "columns_1= batting_match_df.columns.tolist()\n",
        "columns_2= bowling_match_df.columns.tolist()\n",
        "# Print the column names\n",
        "print(columns_1)\n",
        "print(columns_2)\n",
        "\n",
        "# Get the column names as sets\n",
        "columns1 = set(batting_match_df.columns)\n",
        "columns2 = set(bowling_match_df.columns)\n",
        "\n",
        "# Find the common columns\n",
        "common_cols = columns1.intersection(columns2)\n",
        "\n",
        "# Print the number of common columns and their names\n",
        "print(\"Number of common columns:\", len(common_cols))\n",
        "print(\"Common column names:\", list(common_cols))\n"
      ],
      "metadata": {
        "id": "N0Mpz3H2BODz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batting_match_df=batting_match_df.rename(columns={'Runs':'Runs_Scored','Balls':'Balls_Faced','Venue':'Batting_Venue','Temp':'Batting_Temp','Wind':'Batting_Wind','Rain':'Batting_Wind','Cloud':'Batting_Cloud','Pressure':'Batting_Pressure','Overs':'Total_Overs','Url text':'URL_Text'})\n",
        "bowling_match_df=bowling_match_df.rename(columns={'Overs':'Bowler_Over','Runs':'Runs_Conceded','Venue':'Bowling_Venue','Temp':'Bowling_Temp','Wind':'Bowling_Wind','Rain':'Bowling_Wind','Cloud':'Bowling_Cloud','Pressure':'Bowling_Pressure','Url text':'URL_Text'})\n",
        "batting_match_df\n",
        "# bowling_match_df\n",
        "\n",
        "batting_match_df_copy=batting_match_df.copy()\n",
        "batting_match_df=batting_match_df_copy.drop(columns=['Score', 'Result', 'Batting_Session', 'Wickets', 'Name', 'Opposition', 'Total_Overs', 'RPO', 'Bowling_Session', 'URL_Text', 'Innings', 'Toss_Win', 'Ground', 'Date', 'Target'])\n",
        "\n",
        "# Get the column names as sets\n",
        "columns1 = set(batting_match_df.columns)\n",
        "columns2 = set(bowling_match_df.columns)\n",
        "\n",
        "# Find the common columns\n",
        "common_cols = columns1.intersection(columns2)\n",
        "\n",
        "# Print the number of common columns and their names\n",
        "print(\"Number of common columns:\", len(common_cols))\n",
        "print(\"Common column names:\", list(common_cols))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PZTEuOb9h8cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merged batting and bowling match df together\n",
        "batting_bowling_df=pd.merge(bowling_match_df,batting_match_df)\n",
        "batting_bowling_df"
      ],
      "metadata": {
        "id": "UibKjJMln41K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=batting_bowling_df.columns.tolist()\n",
        "print(columns)"
      ],
      "metadata": {
        "id": "7MpFbh4soRAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features Importance for Ann Rating model"
      ],
      "metadata": {
        "id": "T6oD5HO9ooxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace '-' with NaN\n",
        "batting_bowling_df = batting_bowling_df.replace('-', np.nan)\n",
        "\n",
        "# fill NaN values with a numeric value\n",
        "batting_bowling_df = batting_bowling_df.fillna(0)\n",
        "\n",
        "# separate the target variable\n",
        "y = batting_bowling_df['Result']\n",
        "# print(X)\n",
        "X = batting_bowling_df.drop(columns=['Result','Description','URL_Text','Date','Match_id'])\n",
        "# print(X)\n",
        "\n",
        "\n",
        "# encode categorical variables\n",
        "cat_cols = ['Name', 'Batting_Session', 'Batting_Venue','Bowling_Venue', 'Opposition', 'Ground', 'Bowling_Session', 'Toss_Win']\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X[cat_cols].apply(encoder.fit_transform)\n",
        "X_encoded = X_encoded.join(X.drop(cat_cols, axis=1))\n",
        "\n",
        "# print(X_encoded)\n",
        "# print(X_encoded.max())\n",
        "# print(X_encoded.min())\n",
        "\n",
        "# replace infinity with NaN and drop rows containing NaN values\n",
        "X_encoded.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_encoded.dropna(inplace=True)\n",
        "y = y[X_encoded.index]\n",
        "\n",
        "\n",
        "\n",
        "# scale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# print(X_scaled)\n",
        "# feature selection using Random Forest\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "\n",
        "# fit the model on the selected features\n",
        "rfc.fit(X_scaled, y)\n",
        "\n",
        "# get the important feature names\n",
        "feature_names = X_encoded.columns.tolist()\n",
        "\n",
        "\n",
        "# plot feature importance\n",
        "importance = rfc.feature_importances_\n",
        "sorted_idx = np.argsort(importance)\n",
        "\n",
        "plt.barh(range(len(sorted_idx)), importance[sorted_idx])\n",
        "plt.yticks(range(len(sorted_idx)), X_encoded.columns[sorted_idx])\n",
        "plt.xlabel('Random Forest Feature Importance')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Zaia1zQfou5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(batting_bowling_df.columns.tolist())"
      ],
      "metadata": {
        "id": "eLwNjG2G1Gbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run ANN Model for Rating players"
      ],
      "metadata": {
        "id": "gN52oczApbKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "columns = batting_bowling_df.columns.tolist()\n",
        "print(columns)\n",
        "\n",
        "batting_bowling_df = batting_bowling_df.loc[:, ~batting_bowling_df.columns.isin([ 'URL_Text', 'Batting_Venue','Bowling_Venue','Batting_Session','Bowling_Session'])]\n",
        "\n",
        "\n",
        "# Check if the specific column exists\n",
        "if 'Result' in columns:\n",
        "    print('Column exists in dataset!')\n",
        "else:\n",
        "    print('Column does not exist in dataset.')\n",
        "# Split the data into features and target\n",
        "X=batting_bowling_df\n",
        "# X = batting_bowling_df.drop(columns=['Result'],axis=1)\n",
        "y = batting_bowling_df['Result']\n",
        "\n",
        "# Convert string columns to numerical columns using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# for column in X.select_dtypes(include=['object']):\n",
        "#     X[column] = label_encoder.fit_transform(X[column])\n",
        "\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Train a decision tree classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict the probability of winning for each player\n",
        "y_pred_proba = dt.predict_proba(X_test)[:, 1]\n",
        "print(y_pred_proba)\n",
        "\n",
        "# Rate the players based on the predicted probability\n",
        "player_ratings = pd.DataFrame({'Name': X_test.index, 'Rating': y_pred_proba})\n",
        "player_ratings = player_ratings.groupby('Name')['Rating'].mean().reset_index()\n",
        "\n",
        "# pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Display the DataFrame with the 'col1' column's full value\n",
        "print(player_ratings['Rating'].head(100))\n",
        "print(player_ratings)\n",
        "\n",
        "# Evaluate the model performance\n",
        "y_pred = dt.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_error = (conf_matrix[0, 1] + conf_matrix[1, 0]) / np.sum(conf_matrix)\n",
        "sensitivity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[1, 0])\n",
        "specificity = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
        "false_positive_rate = conf_matrix[1, 0] / (conf_matrix[1, 0] + conf_matrix[0, 0])\n",
        "precision = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Accuracy:', accuracy)\n",
        "print('Confusion matrix:', conf_matrix)\n",
        "print('Classification error:', classification_error)\n",
        "print('Sensitivity:', sensitivity)\n",
        "print('Specificity:', specificity)\n",
        "print('False positive rate:', false_positive_rate)\n",
        "print('Precision:', precision)\n"
      ],
      "metadata": {
        "id": "I_6pfXaxqFec"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16Bmv6fGNg-FqKuFr-7wNNn2kpqL_inE6",
      "authorship_tag": "ABX9TyPRVI9WpXlmp9Dh4d4GHEWB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}